# LoRA Alpha Scale Investigation Report

**Date:** 2025-11-10  
**Issue:** Native LongCat LoRA generation looks worse than 16-step normal generation  
**Root Cause:** Multiple bugs in FastVideo's LoRA implementation related to alpha scaling

---

## Executive Summary

FastVideo's LoRA implementation has **critical bugs** that cause LoRA adapters to be applied with **incorrect scaling**. The alpha scaling mechanism is broken in multiple ways:

1. ‚úÖ **Conversion script** loses `alpha_scale` (FIXED)
2. ‚ùå **Inference loading** never reads `alpha_scale` from weights
3. ‚ùå **Weight merging** never applies `alpha/rank` scaling
4. ‚ùå **Forward pass** never applies scaling (alpha/rank are both `None`)

This caused the LongCat distilled LoRA (which uses `alpha_scale=0.5`) to be applied at **2x the intended strength**, resulting in poor generation quality.

---

## Technical Details

### 1. How LoRA Alpha Scaling Should Work

LoRA applies a low-rank adaptation with scaling:

```python
output = base_layer(x) + (x @ lora_A.T @ lora_B.T) * (alpha / rank)
```

Where:
- `lora_A`: Down-projection matrix (rank √ó in_dim)
- `lora_B`: Up-projection matrix (out_dim √ó rank)
- `alpha`: Learning rate scaling factor (hyperparameter)
- `rank`: LoRA rank
- `alpha / rank`: The **alpha_scale** that controls LoRA strength

**LongCat's distilled LoRA uses:** `alpha=64`, `rank=128`, so `alpha_scale = 64/128 = 0.5`

### 2. FastVideo's LoRA Architecture

#### File: `fastvideo/pipelines/lora_pipeline.py`

**Class fields (lines 42-43):**
```python
lora_rank: int | None = None
lora_alpha: int | None = None
```

**Initialization for TRAINING mode (lines 55-63):**
```python
if self.training_mode and getattr(self.fastvideo_args, "lora_training", False):
    if self.fastvideo_args.lora_alpha is None:
        self.fastvideo_args.lora_alpha = self.fastvideo_args.lora_rank
    self.lora_rank = self.fastvideo_args.lora_rank
    self.lora_alpha = self.fastvideo_args.lora_alpha
    logger.info("Using LoRA training with rank %d and alpha %d",
                self.lora_rank, self.lora_alpha)
    self.convert_to_lora_layers()
```

**Initialization for INFERENCE mode (lines 70-75):**
```python
# Inference
elif not self.training_mode and self.lora_path is not None:
    self.convert_to_lora_layers()  # ‚ö†Ô∏è lora_rank and lora_alpha are still None!
    self.set_lora_adapter(
        self.lora_nickname,
        self.lora_path)
```

**‚ùå BUG #1:** In inference mode, `lora_rank` and `lora_alpha` are **never set**, they remain `None`.

---

### 3. Layer Creation

#### File: `fastvideo/pipelines/lora_pipeline.py`

**convert_to_lora_layers (lines 130-133):**
```python
layer = get_lora_layer(layer,
                       lora_rank=self.lora_rank,    # None in inference!
                       lora_alpha=self.lora_alpha,  # None in inference!
                       training_mode=self.training_mode)
```

#### File: `fastvideo/layers/lora/linear.py`

**BaseLayerWithLoRA.__init__ (lines 28-46):**
```python
def __init__(
    self,
    base_layer: nn.Module,
    lora_rank: int | None = None,
    lora_alpha: int | None = None,
    training_mode: bool = False,
):
    super().__init__()
    self.base_layer: nn.Module = base_layer
    self.merged: bool = False
    self.cpu_weight = base_layer.weight.to("cpu")
    self.disable_lora: bool = False
    self.lora_rank = lora_rank     # Stored as None in inference
    self.lora_alpha = lora_alpha   # Stored as None in inference
    self.training_mode = training_mode
    self.lora_path: str | None = None
    # ... rest of init
```

**‚ùå BUG #2:** LoRA layers are created with `lora_rank=None` and `lora_alpha=None` in inference mode.

---

### 4. Loading LoRA Weights

#### File: `fastvideo/pipelines/lora_pipeline.py`

**set_lora_adapter (lines 176-234):**
```python
if lora_path is not None and lora_path != self.cur_adapter_path:
    lora_local_path = maybe_download_lora(lora_path)
    lora_state_dict = load_file(lora_local_path)  # Loads safetensors file
    
    # ... mapping logic ...
    
    for name, weight in lora_state_dict.items():
        name = name.replace("diffusion_model.", "")
        name = name.replace(".weight", "")
        # ... process lora_A and lora_B ...
        
        self.lora_adapters[lora_nickname][target_name] = weight.to(self.device)
```

**‚ùå BUG #3:** The code iterates through `lora_state_dict` but **never reads `alpha_scale` keys**, even if they exist in the file!

**set_lora_adapter (lines 225-234):**
```python
# Merge the new adapter
for name, layer in self.lora_layers.items():
    lora_A_name = name + ".lora_A"
    lora_B_name = name + ".lora_B"
    if lora_A_name in self.lora_adapters[lora_nickname] \
        and lora_B_name in self.lora_adapters[lora_nickname]:
        layer.set_lora_weights(
            self.lora_adapters[lora_nickname][lora_A_name],
            self.lora_adapters[lora_nickname][lora_B_name],
            training_mode=self.fastvideo_args.training_mode,
            lora_path=lora_path)
```

#### File: `fastvideo/layers/lora/linear.py`

**set_lora_weights (lines 101-112):**
```python
def set_lora_weights(self,
                     A: torch.Tensor,
                     B: torch.Tensor,
                     training_mode: bool = False,
                     lora_path: str | None = None) -> None:
    self.lora_A = torch.nn.Parameter(A)
    self.lora_B = torch.nn.Parameter(B)
    self.disable_lora = False
    if not training_mode:
        self.merge_lora_weights()  # Called immediately in inference!
    self.lora_path = lora_path
```

**‚ùå BUG #4:** `set_lora_weights()` doesn't accept or update `lora_alpha` or `lora_rank` parameters!

---

### 5. Weight Merging (Inference Mode)

#### File: `fastvideo/layers/lora/linear.py`

**merge_lora_weights (lines 114-138):**
```python
@torch.no_grad()
def merge_lora_weights(self) -> None:
    if self.disable_lora:
        return
    
    if self.merged:
        self.unmerge_lora_weights()
    assert self.lora_A is not None and self.lora_B is not None
    
    if isinstance(self.base_layer.weight, DTensor):
        # ... DTensor handling ...
        data = self.base_layer.weight.data.to(get_local_torch_device()).full_tensor()
        data += (self.slice_lora_b_weights(self.lora_B).to(data)
                 @ self.slice_lora_a_weights(self.lora_A).to(data))  # ‚ö†Ô∏è NO SCALING!
        unsharded_base_layer.weight = nn.Parameter(data.to(current_device))
        # ... rest of method ...
```

**‚ùå BUG #5:** The critical line `data += B @ A` applies LoRA **WITHOUT any alpha/rank scaling**!

**Should be:**
```python
alpha_scale = self.lora_alpha / self.lora_rank if self.lora_alpha and self.lora_rank else 1.0
data += alpha_scale * (self.slice_lora_b_weights(self.lora_B).to(data)
                       @ self.slice_lora_a_weights(self.lora_A).to(data))
```

---

### 6. Forward Pass (Training Mode / Unmerged)

#### File: `fastvideo/layers/lora/linear.py`

**forward (lines 72-93):**
```python
@torch.compile()
def forward(self, x: torch.Tensor) -> torch.Tensor:
    lora_A = self.lora_A
    lora_B = self.lora_B
    if isinstance(self.lora_B, DTensor):
        lora_B = self.lora_B.to_local()
        lora_A = self.lora_A.to_local()
    
    if not self.merged and not self.disable_lora:
        lora_A_sliced = self.slice_lora_a_weights(lora_A.to(x, non_blocking=True))
        lora_B_sliced = self.slice_lora_b_weights(lora_B.to(x, non_blocking=True))
        delta = x @ lora_A_sliced.T @ lora_B_sliced.T
        if self.lora_alpha != self.lora_rank:  # Both are None in inference!
            delta = delta * (
                self.lora_alpha / self.lora_rank  # Would throw error if executed
            )
        out, output_bias = self.base_layer(x)
        return out + delta, output_bias
    else:
        out, output_bias = self.base_layer(x)
        return out.to(x), output_bias
```

**‚ùå BUG #6:** The condition `if self.lora_alpha != self.lora_rank` would be `None != None` (False) in inference mode, so no scaling is applied even if weights weren't merged!

---

## Summary of Bugs

| Location | Issue | Impact |
|----------|-------|--------|
| **Conversion Script** | Parses but doesn't save `alpha_scale` | ‚úÖ **FIXED** |
| **LoRAPipeline.__init__** | Doesn't set `lora_rank`/`lora_alpha` in inference mode | Layers initialized with `None` |
| **set_lora_adapter** | Never reads `alpha_scale` keys from state dict | Alpha values lost |
| **set_lora_weights** | Doesn't accept alpha parameters | No way to update alpha |
| **merge_lora_weights** | Doesn't apply `alpha/rank` scaling | **LoRA applied with wrong strength** |
| **forward** | Scaling check fails when alpha/rank are `None` | No scaling even if unmerged |

---

## Impact on LongCat

**Original LongCat implementation:**
- Stores `alpha_scale=0.5` in LoRA weights
- Applies this scale when loading: `lora_weight * alpha_scale`
- Result: LoRA effect is scaled by 0.5

**FastVideo native implementation (BEFORE fix):**
- Conversion script loses `alpha_scale`
- Loading ignores `alpha_scale` even if present
- Merging applies `weight += B @ A` (implicitly scale=1.0)
- Result: LoRA effect is scaled by 1.0 (2x too strong!)

**Empirical evidence:**
```
Base models MSE:         2.35e-3  (small difference, expected)
LoRA models MSE:         1.74e-2  (LARGE difference - 7.4x base!)
Native LoRA effect MSE:  1.07e-2  (too strong)
Original LoRA effect:    3.23e-3  (correct strength)
```

After manually applying `scale=0.5`:
```
Base models MSE:         2.35e-3  (unchanged)
LoRA models MSE:         2.95e-3  (‚úì now close to base!)
Native LoRA effect:      8.85e-3  (‚úì now similar to original)
```

---

## Required Fixes

### Fix 1: Conversion Script ‚úÖ (DONE)

**File:** `scripts/checkpoint_conversion/longcat_to_fastvideo.py`

**Lines to change:** 391-466 (function `convert_lora_weights`)

**Change summary:** Add alpha_scale extraction and saving for each layer

```python
def convert_lora_weights(source_weights: dict[str, torch.Tensor], lora_name: str) -> dict[str, torch.Tensor]:
    """Convert LongCat LoRA to FastVideo format."""
    print(f"  Converting {lora_name}...")
    print(f"    Source keys: {len(source_weights)}")
    
    converted = OrderedDict()
    
    # Group by module
    modules = {}
    for key in source_weights.keys():
        try:
            module_path, weight_type = parse_lora_key(key)
            if module_path not in modules:
                modules[module_path] = {}
            modules[module_path][weight_type] = key
        except ValueError:
            continue
    
    # Process each module
    for module_path, weight_keys in modules.items():
        try:
            targets = map_lora_module(module_path)
        except ValueError:
            continue
        
        # ‚úÖ NEW: Get alpha_scale if present (defaults to 1.0 if missing)
        alpha_scale = 1.0
        if "alpha_scale" in weight_keys:
            alpha_scale_tensor = source_weights[weight_keys["alpha_scale"]]
            alpha_scale = alpha_scale_tensor.item() if alpha_scale_tensor.numel() == 1 else float(alpha_scale_tensor.mean())
        
        # Handle lora_down (lora_A)
        if "lora_down.weight" in weight_keys:
            lora_down = source_weights[weight_keys["lora_down.weight"]]
            
            if len(targets) == 1:
                converted[f"{targets[0][0]}.lora_A"] = lora_down
                # ‚úÖ NEW: Save alpha_scale for each layer
                converted[f"{targets[0][0]}.alpha_scale"] = torch.tensor(alpha_scale, dtype=torch.float32)
            else:
                # Split for fused projections
                n = len(targets)
                rank = lora_down.shape[0] // n
                for i, (path, _) in enumerate(targets):
                    converted[f"{path}.lora_A"] = lora_down[i*rank:(i+1)*rank, :]
                    # ‚úÖ NEW: Save alpha_scale for each split layer
                    converted[f"{path}.alpha_scale"] = torch.tensor(alpha_scale, dtype=torch.float32)
        
        # Handle lora_up (lora_B) - may have multiple blocks
        lora_up_blocks = []
        i = 0
        while f"lora_up.blocks.{i}.weight" in weight_keys:
            lora_up_blocks.append(source_weights[weight_keys[f"lora_up.blocks.{i}.weight"]])
            i += 1
        
        if lora_up_blocks:
            lora_up = torch.cat(lora_up_blocks, dim=0)
        elif "lora_up.weight" in weight_keys:
            lora_up = source_weights[weight_keys["lora_up.weight"]]
        else:
            continue
        
        # Split if needed
        if len(targets) == 1:
            converted[f"{targets[0][0]}.lora_B"] = lora_up
        else:
            n = len(targets)
            out_dim = lora_up.shape[0] // n
            for i, (path, _) in enumerate(targets):
                converted[f"{path}.lora_B"] = lora_up[i*out_dim:(i+1)*out_dim, :]
    
    print(f"    Output keys: {len(converted)} (including alpha_scale)")
    # ‚úÖ NEW: Count how many alpha_scale values were added
    alpha_count = sum(1 for k in converted.keys() if "alpha_scale" in k)
    print(f"    Alpha scales saved: {alpha_count}")
    return converted
```

---

### Fix 2: Update set_lora_weights Signature

**File:** `fastvideo/layers/lora/linear.py`

**Lines to change:** 101-112 (function `set_lora_weights`)

**Change summary:** Add alpha_scale parameter and set lora_rank/lora_alpha from it

```python
def set_lora_weights(self,
                     A: torch.Tensor,
                     B: torch.Tensor,
                     alpha_scale: float = 1.0,  # ‚úÖ NEW PARAMETER
                     training_mode: bool = False,
                     lora_path: str | None = None) -> None:
    self.lora_A = torch.nn.Parameter(
        A)  # share storage with weights in the pipeline
    self.lora_B = torch.nn.Parameter(B)
    
    # ‚úÖ NEW: Infer rank from tensor shapes and set alpha from alpha_scale
    # alpha_scale = alpha / rank, so alpha = alpha_scale * rank
    rank = A.shape[0]
    self.lora_rank = rank
    self.lora_alpha = int(alpha_scale * rank)
    
    self.disable_lora = False
    if not training_mode:
        self.merge_lora_weights()
    self.lora_path = lora_path
```

---

### Fix 3: Apply Scaling in merge_lora_weights

**File:** `fastvideo/layers/lora/linear.py`

**Lines to change:** 114-170 (function `merge_lora_weights`)

**Change summary:** Calculate and apply alpha_scale when merging LoRA weights

```python
@torch.no_grad()
def merge_lora_weights(self) -> None:
    if self.disable_lora:
        return

    if self.merged:
        self.unmerge_lora_weights()
    assert self.lora_A is not None and self.lora_B is not None, "LoRA weights not set. Please set them first."
    
    # ‚úÖ NEW: Calculate alpha/rank scaling factor
    if self.lora_alpha is not None and self.lora_rank is not None and self.lora_rank != 0:
        alpha_scale = self.lora_alpha / self.lora_rank
    else:
        alpha_scale = 1.0
    
    if isinstance(self.base_layer.weight, DTensor):
        mesh = self.base_layer.weight.data.device_mesh
        unsharded_base_layer = ReplicatedLinear(
            input_size=self.base_layer.input_size,
            output_size=self.base_layer.output_size,
            bias=getattr(self.base_layer, "bias", None) is not None,
            skip_bias_add=self.base_layer.skip_bias_add,
            params_dtype=self.base_layer.params_dtype,
            quant_config=self.base_layer.quant_config,
            prefix=self.base_layer.prefix,
        )
        # Using offload param is on CPU, so current_device is for "CPU -> GPU -> merge -> CPU"
        current_device = self.base_layer.weight.data.device
        data = self.base_layer.weight.data.to(
            get_local_torch_device()).full_tensor()
        # ‚úÖ CHANGED: Apply alpha_scale
        data += alpha_scale * (self.slice_lora_b_weights(self.lora_B).to(data)
                               @ self.slice_lora_a_weights(self.lora_A).to(data))
        unsharded_base_layer.weight = nn.Parameter(data.to(current_device))
        if isinstance(getattr(self.base_layer, "bias", None), DTensor):
            unsharded_base_layer.bias = nn.Parameter(
                self.base_layer.bias.to(
                    get_local_torch_device(),
                    non_blocking=True).full_tensor().to(current_device))

        offload_policy = CPUOffloadPolicy() if "cpu" in str(
            current_device) else OffloadPolicy()
        mp_policy = get_mixed_precision_state().mp_policy

        self.base_layer = fully_shard(unsharded_base_layer,
                                      mesh=mesh,
                                      mp_policy=mp_policy,
                                      offload_policy=offload_policy)
    else:
        current_device = self.base_layer.weight.data.device
        data = self.base_layer.weight.data.to(get_local_torch_device())
        # ‚úÖ CHANGED: Apply alpha_scale
        data += alpha_scale * \
            (self.slice_lora_b_weights(self.lora_B.to(data)) @ self.slice_lora_a_weights(self.lora_A.to(data)))
        self.base_layer.weight.data = data.to(current_device,
                                              non_blocking=True)

    self.merged = True
```

---

### Fix 4: Read Alpha Scale in set_lora_adapter

**File:** `fastvideo/pipelines/lora_pipeline.py`

**Lines to change:** 158-243 (function `set_lora_adapter`)

**Change summary:** Read alpha_scale from state dict and pass to set_lora_weights

```python
def set_lora_adapter(self,
                     lora_nickname: str,
                     lora_path: str | None = None):  # type: ignore
    """
    Load a LoRA adapter into the pipeline and merge it into the transformer.
    Args:
        lora_nickname: The "nick name" of the adapter when referenced in the pipeline.
        lora_path: The path to the adapter, either a local path or a Hugging Face repo id.
    """

    if lora_nickname not in self.lora_adapters and lora_path is None:
        raise ValueError(
            f"Adapter {lora_nickname} not found in the pipeline. Please provide lora_path to load it."
        )
    if not self.lora_initialized:
        self.convert_to_lora_layers()
    adapter_updated = False
    rank = dist.get_rank()
    if lora_path is not None and lora_path != self.cur_adapter_path:
        lora_local_path = maybe_download_lora(lora_path)
        lora_state_dict = load_file(lora_local_path)

        # Map the hf layer names to our custom layer names
        param_names_mapping_fn = get_param_names_mapping(
            self.modules["transformer"].param_names_mapping)
        lora_param_names_mapping_fn = get_param_names_mapping(
            self.modules["transformer"].lora_param_names_mapping)

        # ‚úÖ NEW: Extract alpha_scale values before processing weights
        alpha_scales = {}
        for name, weight in lora_state_dict.items():
            if "alpha_scale" in name:
                layer_name = name.replace(".alpha_scale", "")
                # Don't apply mappings yet, store with original name
                alpha_scales[layer_name] = weight.item() if weight.numel() == 1 else float(weight.mean())

        to_merge_params: defaultdict[Hashable,
                                     dict[Any, Any]] = defaultdict(dict)
        for name, weight in lora_state_dict.items():
            # ‚úÖ NEW: Skip alpha_scale keys (already extracted)
            if "alpha_scale" in name:
                continue
                
            name = name.replace("diffusion_model.", "")
            name = name.replace(".weight", "")
            name, _, _ = lora_param_names_mapping_fn(name)
            target_name, merge_index, num_params_to_merge = param_names_mapping_fn(
                name)
            # for (in_dim, r) @ (r, out_dim), we only merge (r, out_dim * n) where n is the number of linear layers to fuse
            # see param mapping in HunyuanVideoArchConfig
            if merge_index is not None and "lora_B" in name:
                to_merge_params[target_name][merge_index] = weight
                if len(to_merge_params[target_name]) == num_params_to_merge:
                    # cat at output dim according to the merge_index order
                    sorted_tensors = [
                        to_merge_params[target_name][i]
                        for i in range(num_params_to_merge)
                    ]
                    weight = torch.cat(sorted_tensors, dim=1)
                    del to_merge_params[target_name]
                else:
                    continue

            if target_name in self.lora_adapters[lora_nickname]:
                raise ValueError(
                    f"Target name {target_name} already exists in lora_adapters[{lora_nickname}]"
                )
            self.lora_adapters[lora_nickname][target_name] = weight.to(
                self.device)
        adapter_updated = True
        self.cur_adapter_path = lora_path
        logger.info("Rank %d: loaded LoRA adapter %s", rank, lora_path)

    if not adapter_updated and self.cur_adapter_name == lora_nickname:
        return
    self.cur_adapter_name = lora_nickname

    # Merge the new adapter
    adapted_count = 0
    for name, layer in self.lora_layers.items():
        lora_A_name = name + ".lora_A"
        lora_B_name = name + ".lora_B"
        if lora_A_name in self.lora_adapters[lora_nickname]\
            and lora_B_name in self.lora_adapters[lora_nickname]:
            # ‚úÖ NEW: Get alpha_scale for this layer (default to 1.0)
            alpha_scale = alpha_scales.get(name, 1.0)
            
            layer.set_lora_weights(
                self.lora_adapters[lora_nickname][lora_A_name],
                self.lora_adapters[lora_nickname][lora_B_name],
                alpha_scale=alpha_scale,  # ‚úÖ NEW PARAMETER
                training_mode=self.fastvideo_args.training_mode,
                lora_path=lora_path)
            adapted_count += 1
        else:
            if rank == 0:
                logger.warning(
                    "LoRA adapter %s does not contain the weights for layer %s. LoRA will not be applied to it.",
                    lora_path, name)
            layer.disable_lora = True
    logger.info("Rank %d: LoRA adapter %s applied to %d layers", rank,
                lora_path, adapted_count)
```

---

## Testing Plan

1. ‚úÖ **Verify conversion script** saves alpha_scale
2. ‚¨ú **Reconvert LoRA weights** with fixed script
3. ‚¨ú **Run layer-by-layer comparison** with new weights
4. ‚¨ú **Test full inference** with `test_longcat_lora_inference.py`
5. ‚¨ú **Visual quality check** of generated videos
6. ‚¨ú **Compare with original LongCat** distilled outputs

---

## Why Doesn't FastVideo Support Alpha Scaling in Inference?

### Answer: It DOES Support It, But Only for Training

After investigating the implementation across all FastVideo models, here's what I found:

#### ‚úÖ Training Mode (WORKING)

**File: `fastvideo/layers/lora/linear.py`**

Lines 48-66 show that training mode properly initializes `lora_rank` and `lora_alpha`:

```python
if training_mode:
    assert self.lora_rank is not None, "LoRA rank must be set for training mode"
    if self.lora_rank is None or self.lora_alpha is None:
        self.lora_alpha = lora_rank  # Defaults alpha to rank
    # ... initialize lora_A and lora_B with zeros ...
```

Lines 85-88 show the forward pass applies alpha scaling **ONLY in training mode**:

```python
if not self.merged and not self.disable_lora:
    delta = x @ lora_A_sliced.T @ lora_B_sliced.T
    if self.lora_alpha != self.lora_rank:  # Only applies if alpha != rank
        delta = delta * (self.lora_alpha / self.lora_rank)
```

**Evidence:** Training scripts use `--lora_rank 32 --lora_training True` and work correctly.

#### ‚ùå Inference Mode (BROKEN)

**Why it's broken:**

1. **Lines 67-69**: In inference mode, `lora_A` and `lora_B` remain `None` until `set_lora_weights()` is called
2. **Lines 101-112**: `set_lora_weights()` NEVER sets `lora_rank` or `lora_alpha`
3. **Line 110**: It immediately calls `merge_lora_weights()` which merges without alpha scaling
4. **Lines 137-138, 157-158**: The merge just does `weight += B @ A` (no alpha factor!)
5. **Result**: After merging, `self.merged = True`, so forward pass takes the `else` branch (line 92) and never applies alpha scaling

**Evidence:** All LoRA inference examples (Wan, LongCat) suffer from this bug, but it's not noticed because:
- Most HuggingFace LoRAs use `alpha = rank`, so `alpha_scale = 1.0` (no scaling needed)
- LongCat is the **first FastVideo model** to use `alpha = 64, rank = 128` (alpha_scale = 0.5)

### Comparison with Other Models

I checked all FastVideo models:

| Model | LoRA Training | LoRA Inference | Alpha Scale Issue |
|-------|--------------|----------------|-------------------|
| **Wan 1.3B** | ‚úÖ Works | ‚úÖ Works (alpha=rank by default) | Not noticed |
| **Wan 14B** | ‚úÖ Works | ‚úÖ Works (alpha=rank by default) | Not noticed |
| **LongCat** | N/A | ‚ùå **Broken** (alpha‚â†rank) | **Discovered!** |

### Root Cause Summary

**FastVideo's LoRA was designed for training, not inference:**
- Training mode keeps LoRA unmerged and applies alpha scaling in `forward()`
- Inference mode merges LoRA into base weights for performance, but **forgot to apply alpha scaling during merge**
- This bug went unnoticed because all existing models happened to use `alpha = rank`

**LongCat exposed this bug** because it's the first model with `alpha ‚â† rank`.

---

## Conclusion

FastVideo's LoRA implementation **does support alpha scaling, but ONLY in training mode**. Inference mode has a fundamental design flaw:

### The Bug
1. **Merges without scaling**: `merge_lora_weights()` does `weight += B @ A` instead of `weight += (alpha/rank) * (B @ A)`
2. **Loses metadata**: Never sets `lora_rank` or `lora_alpha` from loaded weights
3. **Skips forward scaling**: After merging, `forward()` uses merged weights and never applies alpha factor

### Why It Went Unnoticed
- **Wan models**: All HF LoRAs use `alpha = rank`, so `alpha_scale = 1.0` (effectively no scaling)
- **Training**: Works fine because LoRA stays unmerged and `forward()` applies scaling
- **LongCat**: First model to use `alpha ‚â† rank`, exposing the 2-year-old bug!

### The Fix
All changes are documented above with exact file paths, line numbers, and code snippets:
1. ‚úÖ **Conversion script** - Save alpha_scale values (DONE)
2. ‚¨ú **LoRA pipeline** - Read alpha_scale from state dict
3. ‚¨ú **set_lora_weights** - Accept and store alpha_scale parameter  
4. ‚¨ú **merge_lora_weights** - Apply alpha/rank scaling during merge

Without these fixes, **any LoRA with alpha ‚â† rank will be applied incorrectly**, leading to poor generation quality.

---

## Summary for User

**Question:** "Why does FastVideo not support alpha scales?"

**Answer:** FastVideo DOES support alpha scaling, but **only for training mode**. The inference mode has a fundamental bug:

1. ‚úÖ **Training Mode**: Works perfectly
   - Keeps LoRA weights separate
   - Applies `alpha/rank` scaling in `forward()` 
   - Used by all Wan training scripts

2. ‚ùå **Inference Mode**: Broken for `alpha ‚â† rank`
   - Merges LoRA into base weights (for speed)
   - **BUG**: Forgets to apply `alpha/rank` scaling during merge
   - **BUG**: Never reads/stores alpha values from weight files

3. üéØ **Why You Discovered This**:
   - All existing FastVideo LoRAs (Wan, etc.) use `alpha = rank` ‚Üí no visible bug
   - LongCat uses `alpha = 64, rank = 128` ‚Üí 2x wrong strength ‚Üí **poor quality!**
   - You're the first to hit this edge case!

**The fix is straightforward** - just need to:
1. Save `alpha_scale` in converted weights ‚úÖ DONE
2. Read `alpha_scale` when loading LoRA
3. Apply `alpha_scale` when merging weights

All specific code changes are documented above with file paths and line numbers.
