#!/usr/bin/env python3
"""
LongCat BSA (Block Sparse Attention) ä½¿ç”¨ç¤ºä¾‹

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†å¦‚ä½•åœ¨ FastVideo çš„ LongCat å®ç°ä¸­ä½¿ç”¨ BSAã€‚
"""

import os
import sys

# æ·»åŠ  FastVideo åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from fastvideo.entrypoints.video_generator import VideoGenerator


def example_1_basic_usage():
    """ç¤ºä¾‹ 1: åŸºç¡€ä½¿ç”¨ - ä»é¢„é…ç½®çš„æƒé‡åŠ è½½"""
    print("=" * 80)
    print("ç¤ºä¾‹ 1: åŸºç¡€ä½¿ç”¨ - BSA åœ¨ config.json ä¸­é¢„é…ç½®")
    print("=" * 80)
    
    # å‡è®¾ä½ çš„ transformer/config.json ä¸­å·²ç»è®¾ç½®äº†:
    # {
    #   "enable_bsa": true,
    #   "bsa_params": {
    #     "sparsity": 0.9375,
    #     "chunk_3d_shape_q": [4, 4, 4],
    #     "chunk_3d_shape_k": [4, 4, 4]
    #   }
    # }
    
    model_path = "/path/to/longcat-weights-with-bsa"
    
    # åŠ è½½æ¨¡å‹ï¼ˆBSA ä¼šè‡ªåŠ¨å¯ç”¨ï¼‰
    generator = VideoGenerator.from_pretrained(
        model_path,
        num_gpus=1
    )
    
    # ç”Ÿæˆ 720p è§†é¢‘
    output = generator.generate_video(
        prompt="A majestic eagle soaring through the mountains",
        height=720,
        width=1280,
        num_frames=93,
        num_inference_steps=50,
        guidance_scale=4.0,
        save_video=True,
        output_path="outputs/eagle_720p_bsa.mp4"
    )
    
    print(f"âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ: {output['output_path']}")
    print(f"ğŸ“Š ç”Ÿæˆæ—¶é—´: {output.get('generation_time', 'N/A')}")


def example_2_runtime_enable():
    """ç¤ºä¾‹ 2: è¿è¡Œæ—¶å¯ç”¨ BSA"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 2: è¿è¡Œæ—¶åŠ¨æ€å¯ç”¨ BSA")
    print("=" * 80)
    
    model_path = "/path/to/longcat-weights"
    
    # åŠ è½½æ¨¡å‹
    generator = VideoGenerator.from_pretrained(model_path, num_gpus=1)
    
    # è·å– transformer æ¨¡å—
    transformer = generator.executor.pipeline.get_module("transformer")
    
    # æ£€æŸ¥æ˜¯å¦æ”¯æŒ BSA
    if hasattr(transformer, 'enable_bsa'):
        print("âœ… Transformer æ”¯æŒ BSA")
        
        # å¯ç”¨ BSA
        transformer.enable_bsa()
        print("âœ… BSA å·²å¯ç”¨")
        
        # æ£€æŸ¥ BSA å‚æ•°
        if hasattr(transformer, 'blocks') and len(transformer.blocks) > 0:
            first_block_attn = transformer.blocks[0].attn
            print(f"ğŸ“‹ enable_bsa: {first_block_attn.enable_bsa}")
            print(f"ğŸ“‹ bsa_params: {first_block_attn.bsa_params}")
    else:
        print("âŒ Transformer ä¸æ”¯æŒ BSA")
        return
    
    # ç”Ÿæˆè§†é¢‘
    output = generator.generate_video(
        prompt="A serene lake at sunset with reflections",
        height=720,
        width=1280,
        num_frames=93,
        num_inference_steps=50,
        guidance_scale=4.0,
        save_video=True,
        output_path="outputs/lake_720p_bsa_runtime.mp4"
    )
    
    print(f"âœ… è§†é¢‘ç”Ÿæˆå®Œæˆ: {output['output_path']}")
    
    # å¯é€‰ï¼šç¦ç”¨ BSAï¼ˆä¸‹æ¬¡ç”Ÿæˆæ—¶ä¸ä½¿ç”¨ï¼‰
    # transformer.disable_bsa()
    # print("BSA å·²ç¦ç”¨")


def example_3_custom_config():
    """ç¤ºä¾‹ 3: ä½¿ç”¨è‡ªå®šä¹‰ BSA é…ç½®"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 3: è‡ªå®šä¹‰ BSA é…ç½®")
    print("=" * 80)
    
    from fastvideo.configs.pipelines.longcat import (
        LongCatT2V480PConfig,
        LongCatDiTArchConfig
    )
    from fastvideo.configs.models import DiTConfig
    from dataclasses import dataclass, field
    
    # åˆ›å»ºè‡ªå®šä¹‰é…ç½®
    @dataclass
    class CustomBSAConfig(LongCatT2V480PConfig):
        enable_bsa: bool = True
        
        dit_config: DiTConfig = field(default_factory=lambda: DiTConfig(
            arch_config=LongCatDiTArchConfig(
                enable_bsa=True,
                bsa_params={
                    "sparsity": 0.90,  # é™ä½ç¨€ç–åº¦ä»¥æé«˜è´¨é‡
                    "cdf_threshold": None,
                    "chunk_3d_shape_q": [4, 4, 8],  # æ›´å¤§çš„ç©ºé—´å—
                    "chunk_3d_shape_k": [4, 4, 8],
                }
            )
        ))
    
    # æ³¨æ„ï¼šè¿™ç§æ–¹å¼éœ€è¦åœ¨åˆ›å»º VideoGenerator ä¹‹å‰è®¾ç½®é…ç½®
    # å®é™…ä½¿ç”¨ä¸­ï¼Œæ¨èåœ¨ config.json ä¸­è®¾ç½®æˆ–ä½¿ç”¨è¿è¡Œæ—¶å¯ç”¨æ–¹å¼
    print("ğŸ“‹ è‡ªå®šä¹‰ BSA é…ç½®:")
    print(f"  - sparsity: 0.90")
    print(f"  - chunk_3d_shape: [4, 4, 8]")
    print("\næç¤º: è¦ä½¿ç”¨æ­¤é…ç½®ï¼Œè¯·åœ¨ transformer/config.json ä¸­è®¾ç½®è¿™äº›å‚æ•°")


def example_4_compare_performance():
    """ç¤ºä¾‹ 4: å¯¹æ¯” BSA å¼€å¯å’Œå…³é—­çš„æ€§èƒ½"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 4: BSA æ€§èƒ½å¯¹æ¯”")
    print("=" * 80)
    
    import time
    import torch
    
    model_path = "/path/to/longcat-weights"
    generator = VideoGenerator.from_pretrained(model_path, num_gpus=1)
    transformer = generator.executor.pipeline.get_module("transformer")
    
    if not hasattr(transformer, 'enable_bsa'):
        print("âŒ Transformer ä¸æ”¯æŒ BSAï¼Œè·³è¿‡å¯¹æ¯”")
        return
    
    test_prompt = "A cat playing with a ball"
    test_config = {
        "prompt": test_prompt,
        "height": 720,
        "width": 1280,
        "num_frames": 93,
        "num_inference_steps": 20,  # ä½¿ç”¨è¾ƒå°‘æ­¥æ•°ä»¥åŠ å¿«æµ‹è¯•
        "guidance_scale": 4.0,
        "save_video": False,
    }
    
    # æµ‹è¯• 1: ä¸ä½¿ç”¨ BSA
    print("\nğŸ”„ æµ‹è¯• 1: ä¸ä½¿ç”¨ BSA")
    transformer.disable_bsa()
    torch.cuda.reset_peak_memory_stats()
    start_time = time.time()
    
    output_no_bsa = generator.generate_video(**test_config)
    
    time_no_bsa = time.time() - start_time
    mem_no_bsa = torch.cuda.max_memory_allocated() / 1024**3  # GB
    
    print(f"â±ï¸  æ—¶é—´: {time_no_bsa:.2f}s")
    print(f"ğŸ’¾ å³°å€¼æ˜¾å­˜: {mem_no_bsa:.2f} GB")
    
    # æ¸…ç†æ˜¾å­˜
    torch.cuda.empty_cache()
    
    # æµ‹è¯• 2: ä½¿ç”¨ BSA
    print("\nğŸ”„ æµ‹è¯• 2: ä½¿ç”¨ BSA")
    transformer.enable_bsa()
    torch.cuda.reset_peak_memory_stats()
    start_time = time.time()
    
    output_with_bsa = generator.generate_video(**test_config)
    
    time_with_bsa = time.time() - start_time
    mem_with_bsa = torch.cuda.max_memory_allocated() / 1024**3  # GB
    
    print(f"â±ï¸  æ—¶é—´: {time_with_bsa:.2f}s")
    print(f"ğŸ’¾ å³°å€¼æ˜¾å­˜: {mem_with_bsa:.2f} GB")
    
    # å¯¹æ¯”ç»“æœ
    print("\nğŸ“Š å¯¹æ¯”ç»“æœ:")
    print(f"âš¡ é€Ÿåº¦æå‡: {time_no_bsa / time_with_bsa:.2f}x")
    print(f"ğŸ’¾ æ˜¾å­˜èŠ‚çœ: {mem_no_bsa - mem_with_bsa:.2f} GB ({(1 - mem_with_bsa/mem_no_bsa)*100:.1f}%)")
    
    if time_with_bsa < time_no_bsa * 0.9:
        print("âœ… BSA å¸¦æ¥äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ï¼")
    else:
        print("â„¹ï¸  BSA åœ¨æ­¤é…ç½®ä¸‹æ€§èƒ½æå‡æœ‰é™")


def example_5_adaptive_bsa():
    """ç¤ºä¾‹ 5: æ ¹æ®åˆ†è¾¨ç‡è‡ªé€‚åº”ä½¿ç”¨ BSA"""
    print("\n" + "=" * 80)
    print("ç¤ºä¾‹ 5: è‡ªé€‚åº” BSA ç­–ç•¥")
    print("=" * 80)
    
    model_path = "/path/to/longcat-weights"
    generator = VideoGenerator.from_pretrained(model_path, num_gpus=1)
    transformer = generator.executor.pipeline.get_module("transformer")
    
    def generate_with_adaptive_bsa(prompt, height, width, **kwargs):
        """æ ¹æ®åˆ†è¾¨ç‡è‡ªé€‚åº”å¯ç”¨ BSA"""
        
        # ç­–ç•¥ï¼š720p åŠä»¥ä¸Šä½¿ç”¨ BSA
        use_bsa = height >= 720
        
        if hasattr(transformer, 'enable_bsa'):
            if use_bsa:
                transformer.enable_bsa()
                print(f"âœ… {height}p: å¯ç”¨ BSA")
            else:
                transformer.disable_bsa()
                print(f"â„¹ï¸  {height}p: ä¸ä½¿ç”¨ BSAï¼ˆåˆ†è¾¨ç‡è¾ƒä½ï¼‰")
        
        return generator.generate_video(
            prompt=prompt,
            height=height,
            width=width,
            **kwargs
        )
    
    # ç”Ÿæˆä¸åŒåˆ†è¾¨ç‡çš„è§†é¢‘
    test_cases = [
        ("480p", 480, 832),
        ("720p", 720, 1280),
    ]
    
    for name, height, width in test_cases:
        print(f"\nğŸ¬ ç”Ÿæˆ {name} è§†é¢‘...")
        output = generate_with_adaptive_bsa(
            prompt="A beautiful sunrise over mountains",
            height=height,
            width=width,
            num_frames=49,
            num_inference_steps=30,
            guidance_scale=4.0,
            save_video=True,
            output_path=f"outputs/sunrise_{name}_adaptive.mp4"
        )
        print(f"âœ… {name} å®Œæˆ: {output['output_path']}")


def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    import argparse
    
    parser = argparse.ArgumentParser(description="LongCat BSA ä½¿ç”¨ç¤ºä¾‹")
    parser.add_argument(
        "--example",
        type=int,
        choices=[1, 2, 3, 4, 5],
        help="è¿è¡ŒæŒ‡å®šçš„ç¤ºä¾‹ (1-5)ï¼Œä¸æŒ‡å®šåˆ™æ˜¾ç¤ºæ‰€æœ‰ç¤ºä¾‹è¯´æ˜"
    )
    
    args = parser.parse_args()
    
    examples = {
        1: ("åŸºç¡€ä½¿ç”¨", example_1_basic_usage),
        2: ("è¿è¡Œæ—¶å¯ç”¨", example_2_runtime_enable),
        3: ("è‡ªå®šä¹‰é…ç½®", example_3_custom_config),
        4: ("æ€§èƒ½å¯¹æ¯”", example_4_compare_performance),
        5: ("è‡ªé€‚åº”ç­–ç•¥", example_5_adaptive_bsa),
    }
    
    if args.example:
        # è¿è¡ŒæŒ‡å®šç¤ºä¾‹
        name, func = examples[args.example]
        print(f"\nè¿è¡Œç¤ºä¾‹ {args.example}: {name}\n")
        func()
    else:
        # æ˜¾ç¤ºæ‰€æœ‰ç¤ºä¾‹è¯´æ˜
        print("LongCat BSA ä½¿ç”¨ç¤ºä¾‹")
        print("=" * 80)
        print("\nå¯ç”¨ç¤ºä¾‹:")
        for num, (name, _) in examples.items():
            print(f"  {num}. {name}")
        print("\nè¿è¡Œæ–¹å¼:")
        print("  python longcat_bsa_usage.py --example <num>")
        print("\nç¤ºä¾‹:")
        print("  python longcat_bsa_usage.py --example 2  # è¿è¡Œç¤ºä¾‹ 2")
        print("\næ³¨æ„: è¿è¡Œå‰è¯·ä¿®æ”¹ model_path ä¸ºä½ çš„å®é™…æ¨¡å‹è·¯å¾„")


if __name__ == "__main__":
    main()

